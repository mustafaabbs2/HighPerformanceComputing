{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "  \n",
                "# Add with a single thread on the GPU\n",
                "\n",
                "import pycuda.driver as cuda\n",
                "import pycuda.autoinit\n",
                "from pycuda.compiler import SourceModule\n",
                "\n",
                "import numpy\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Should be 100\n",
                        "Results: 100\n"
                    ]
                }
            ],
            "source": [
                "# Define CUDA function\n",
                "mod = SourceModule(\"\"\"\n",
                "__global__ void add(int *a, int *b, int *c)  {\n",
                "  int id = blockIdx.x;\n",
                "  c[id] = a[id] + b[id];\n",
                "}\"\"\")\n",
                "\n",
                "func = mod.get_function(\"add\")\n",
                "\n",
                "# Vector size\n",
                "N = 100\n",
                "\n",
                "# Host vectors\n",
                "a = numpy.array(range(0,N))\n",
                "b = 1 - a\n",
                "c = numpy.zeros(N)\n",
                "\n",
                "a = a.astype(numpy.int32)\n",
                "b = b.astype(numpy.int32)\n",
                "c = c.astype(numpy.int32)\n",
                "\n",
                "# Allocate on device\n",
                "a_gpu = cuda.mem_alloc(a.size * a.dtype.itemsize)\n",
                "b_gpu = cuda.mem_alloc(b.size * b.dtype.itemsize)\n",
                "c_gpu = cuda.mem_alloc(c.size * c.dtype.itemsize)\n",
                "\n",
                "# Copy from host to device\n",
                "cuda.memcpy_htod(a_gpu, a)\n",
                "cuda.memcpy_htod(b_gpu, b)\n",
                "\n",
                "func(a_gpu, b_gpu, c_gpu, block=(1,1,1), grid=(N,1))\n",
                "\n",
                "# Copy result to host\n",
                "cuda.memcpy_dtoh(c, c_gpu)\n",
                "\n",
                "# Display results\n",
                "print(\"Should be %d\" % N)\n",
                "print(\"Results: %d\" % numpy.sum(c))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'pycuda'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpycuda\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgpuarray\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgpuarray\u001b[39;00m \n\u001b[0;32m      2\u001b[0m a_gpu \u001b[38;5;241m=\u001b[39m gpuarray\u001b[38;5;241m.\u001b[39mto_gpu(numpy\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(numpy\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[0;32m      3\u001b[0m a_doubled \u001b[38;5;241m=\u001b[39m (a_gpu)\u001b[38;5;241m.\u001b[39mget()\n",
                        "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pycuda'"
                    ]
                }
            ],
            "source": [
                "import pycuda.gpuarray as gpuarray \n",
                "a_gpu = gpuarray.to_gpu(numpy.random.randn(4,4).astype(numpy.float32))\n",
                "a_doubled = (a_gpu).get()\n",
                "print(a_doubled)\n",
                "print(a_gpu)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "31975310e00e99f57aeed412d6ffb9743c7c73cc4e7d67665efbf43b79b6a0d8"
        },
        "kernelspec": {
            "display_name": "Python 3.6.13 64-bit ('base': conda)",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.13"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
